\section{Theoretical validation}
\begin{frame}{\secname}
	\framesubtitle{System identification basic}
	\begin{columns}
		\begin{column}{0.5\textwidth}
			\begin{itemize}
				\item Assume that a data set $Z^N = \{u[n],y[n]|n=1\ldots N\}$ has been collected.
				\item The dataset $Z^N$ is assumed generated by
					\begin{equation}
						\mathcal{S}: y[n] = G_0(z,\theta_0)u[n] + H_0(z,\theta_0)e[n]
					\end{equation}
				\item Using the data set $Z^N$ we want to find the parameter vector $\theta^N$ minimizing
\begin{equation}\label{eq:pred}
		\hat{\theta}_N = \argmin_{\theta} \frac{1}{N}\sum_{n=1}^N \epsilon^2(n,\theta)
\end{equation}
			\end{itemize}
		\end{column}
		\begin{column}{0.5\textwidth}
			\begin{figure}
				\includegraphics{./pictures/v_block.tikz}
			\end{figure}
		\end{column}
	\end{columns}
\end{frame}
\begin{frame}{\secname}
	\framesubtitle{Consistency}
	\begin{itemize}
	\item A consistent estimate means that the true parameter vector $\theta_0$ is the unique solution to the asymptotic prediction error criterion.
\begin{equation}\label{eq:theta_1}
		\theta^*= \argmin_{\theta} \bar{E}\epsilon^2(n,\theta)
\end{equation}
with
\begin{equation}
		\bar{E}\epsilon^2(n,\theta) = \lim_{N\to\infty}\frac{1}{N}\sum_{t=1}^N E\epsilon^2(n,\theta)
\end{equation}
and
\begin{equation}\label{eq:epsi}
		\epsilon(n,\theta)=H_1^{-1}(z,\theta)(y[n]-G_1(z,\theta)u[n])
\end{equation}
\end{itemize}
\end{frame}
\begin{frame}{\secname}
		\framesubtitle{System identification basics take away}
			\begin{itemize}
				\item<1-> Define what one wants to identify.
				\item<2-> Define the input and outputs of the system.
				\item<3-> Prove that one will obtain a consistent estimate using the selected inputs and outputs.
				\item<4->\emph{\color{red}The input and output have to be modeled to do this}
			\end{itemize}
\end{frame}
\section{Definition of identification problem}
\begin{frame}{\secname}
	\framesubtitle{Choice of input and output to the identification problem}
		\begin{figure}[t]
			\includegraphics<1-3>{./pictures/PID.tikz}
			\includegraphics<4->{./pictures/genTrafo.tikz}
		\end{figure}
	\begin{itemize}
		\item<1-> Preferably we would use:
			\begin{itemize}
				\item<2-> $\Delta \omega_1[n]$ as input and,
				\item<3-> $\Delta P_{m1}[n]$ as output.
			\end{itemize}
		\item<4-> However, the TSO has only access to
			\begin{itemize}
				\item<5-> $\Delta \omega_3[n]$ and,
				\item<6-> $\Delta P_{e3}[n]$.
			\end{itemize}
	\end{itemize}
\end{frame}
\begin{frame}{\secname}
	\framesubtitle{Assumptions regarding input and output}
	\begin{itemize}
		\item We assume that the PMU is situated sufficiently close to the generator such that:
		\begin{itemize}
			\item $\Delta \omega_1[n] \approx \Delta \omega_3[n]$ and,
			\item $\Delta P_{e1}[n] \approx \Delta P_{e3}[n]$.
		\end{itemize}
		\item The electrical power is related to the mechanical power by the swing equation:
			\begin{equation}\label{eq:swing}
				\Delta \omega_1(s) = \frac{\Delta P_{m1}(s) - \Delta P_{e1}(s)}{2\mathcal{H}_1s+K_{d1}}
			\end{equation}
	\end{itemize}
\end{frame}
\begin{frame}{\secname}
	\framesubtitle{Transfer function that can be identified using PMUs}
	\begin{itemize}
		\item We now introduce the following transfer functions:
			\begin{itemize}
				\item The turbine and governor dynamics are described by $G_{t1}(s)$ and,
				\item $G_{J1}(s) = 1/(2\mathcal{H}_1s+K_{d1})$
			\end{itemize}
		\item We can now write the angular speed as:
			\begin{equation}\label{eq:f1}
				\Delta \omega_1(s) = -\frac{G_{J1}(s)}{1+G_{J1}(s)G_{t1}(s)} \Delta P_{e1}(s) + v_1(s)
			\end{equation}
		\item The transfer function $G_1(s)$ we can identify is therefore:
			\begin{equation}
					G_1(s) = -\frac{G_{J1}(s)}{1+G_{t1}(s)G_{J1}(s)}
			\end{equation}
	\end{itemize}
\end{frame}
